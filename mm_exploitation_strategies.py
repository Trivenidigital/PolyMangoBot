"""
Market Maker Exploitation Strategies
Advanced strategies for detecting and exploiting MM behavior patterns.

Strategies:
1. Inventory-Based Fading - Trade against MM extreme inventory
2. Spread Regime Detection - Identify spread regimes for optimal entry
3. Quote Stuffing Detection - Detect manipulation and adjust accordingly
"""

import asyncio
import numpy as np
import time
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import deque
from enum import Enum
from datetime import datetime, timedelta

logger = logging.getLogger("PolyMangoBot.mm_exploitation")


# =============================================================================
# ENUMS AND DATA CLASSES
# =============================================================================

class SpreadRegime(Enum):
    """Spread regime classifications"""
    ULTRA_TIGHT = "ultra_tight"      # < 1bp - Highly competitive
    TIGHT = "tight"                   # 1-3bp - Normal liquid
    NORMAL = "normal"                 # 3-10bp - Average
    WIDE = "wide"                     # 10-25bp - Low liquidity
    VERY_WIDE = "very_wide"          # 25-50bp - Distressed
    EXTREME = "extreme"               # > 50bp - Crisis


class QuoteStuffingType(Enum):
    """Types of quote stuffing detected"""
    NONE = "none"
    LAYERING = "layering"             # False liquidity layers
    SPOOFING = "spoofing"             # Large fake orders
    FLICKERING = "flickering"         # Rapid quote changes
    MOMENTUM_IGNITION = "momentum_ignition"  # Trigger algos
    WASH_TRADING = "wash_trading"     # Self-trading


class FadeSignalStrength(Enum):
    """Strength of fade signal"""
    NONE = "none"
    WEAK = "weak"
    MODERATE = "moderate"
    STRONG = "strong"
    VERY_STRONG = "very_strong"


@dataclass
class InventoryFadeSignal:
    """Signal from inventory-based fading strategy"""
    direction: str                    # "buy", "sell", or "neutral"
    strength: FadeSignalStrength
    confidence: float

    # MM state
    mm_inventory_estimate: float
    mm_inventory_zscore: float
    inventory_reversion_probability: float

    # Timing
    optimal_entry_delay_ms: float
    expected_reversion_time_ms: float

    # Risk
    risk_score: float
    max_position_pct: float           # Suggested max position as % of liquidity

    # Price targets
    entry_price: float
    target_price: float
    stop_loss: float
    expected_profit_bps: float

    timestamp: float = field(default_factory=time.time)

    def to_dict(self) -> Dict:
        return {
            "direction": self.direction,
            "strength": self.strength.value,
            "confidence": self.confidence,
            "mm_inventory_estimate": self.mm_inventory_estimate,
            "mm_inventory_zscore": self.mm_inventory_zscore,
            "inventory_reversion_probability": self.inventory_reversion_probability,
            "optimal_entry_delay_ms": self.optimal_entry_delay_ms,
            "expected_reversion_time_ms": self.expected_reversion_time_ms,
            "risk_score": self.risk_score,
            "max_position_pct": self.max_position_pct,
            "entry_price": self.entry_price,
            "target_price": self.target_price,
            "stop_loss": self.stop_loss,
            "expected_profit_bps": self.expected_profit_bps,
            "timestamp": self.timestamp
        }


@dataclass
class SpreadRegimeAnalysis:
    """Analysis of current spread regime"""
    current_regime: SpreadRegime
    regime_confidence: float
    regime_duration_seconds: float

    # Spread metrics
    current_spread_bps: float
    avg_spread_bps: float
    spread_volatility: float
    spread_percentile: float          # 0-100, where spread sits historically

    # Regime transition probabilities
    tightening_probability: float
    widening_probability: float
    stable_probability: float

    # Timing signals
    is_optimal_entry: bool
    entry_score: float                # 0-1, how good is current entry timing
    wait_for_tightening: bool
    expected_wait_ms: float

    # Historical regime stats
    avg_regime_duration_seconds: float
    regime_transition_rate: float     # Transitions per hour

    timestamp: float = field(default_factory=time.time)

    def to_dict(self) -> Dict:
        return {
            "current_regime": self.current_regime.value,
            "regime_confidence": self.regime_confidence,
            "regime_duration_seconds": self.regime_duration_seconds,
            "current_spread_bps": self.current_spread_bps,
            "avg_spread_bps": self.avg_spread_bps,
            "spread_volatility": self.spread_volatility,
            "spread_percentile": self.spread_percentile,
            "tightening_probability": self.tightening_probability,
            "widening_probability": self.widening_probability,
            "stable_probability": self.stable_probability,
            "is_optimal_entry": self.is_optimal_entry,
            "entry_score": self.entry_score,
            "wait_for_tightening": self.wait_for_tightening,
            "expected_wait_ms": self.expected_wait_ms,
            "avg_regime_duration_seconds": self.avg_regime_duration_seconds,
            "regime_transition_rate": self.regime_transition_rate,
            "timestamp": self.timestamp
        }


@dataclass
class QuoteStuffingAlert:
    """Alert for detected quote stuffing"""
    stuffing_type: QuoteStuffingType
    confidence: float
    severity: float                   # 0-1, how severe

    # Detection metrics
    quote_rate_per_second: float
    cancel_rate_per_second: float
    quote_to_trade_ratio: float

    # Affected levels
    affected_price_levels: List[float]
    fake_liquidity_estimate: float    # Estimated fake volume

    # Recommendations
    should_pause_trading: bool
    reduce_aggression: bool
    ignore_levels: List[float]        # Price levels to ignore

    # Attribution
    likely_source: str                # "unknown", "mm", "algo", etc.

    timestamp: float = field(default_factory=time.time)
    duration_ms: float = 0.0

    def to_dict(self) -> Dict:
        return {
            "stuffing_type": self.stuffing_type.value,
            "confidence": self.confidence,
            "severity": self.severity,
            "quote_rate_per_second": self.quote_rate_per_second,
            "cancel_rate_per_second": self.cancel_rate_per_second,
            "quote_to_trade_ratio": self.quote_to_trade_ratio,
            "affected_price_levels": self.affected_price_levels,
            "fake_liquidity_estimate": self.fake_liquidity_estimate,
            "should_pause_trading": self.should_pause_trading,
            "reduce_aggression": self.reduce_aggression,
            "ignore_levels": self.ignore_levels,
            "likely_source": self.likely_source,
            "timestamp": self.timestamp,
            "duration_ms": self.duration_ms
        }


@dataclass
class QuoteEvent:
    """Single quote event for tracking"""
    price: float
    quantity: float
    side: str                         # "bid" or "ask"
    event_type: str                   # "add", "modify", "cancel"
    timestamp: float
    level: int = 0                    # Book level (0 = top of book)


@dataclass
class TradeEvent:
    """Trade event for quote-to-trade ratio"""
    price: float
    quantity: float
    side: str
    timestamp: float


# =============================================================================
# INVENTORY-BASED FADING STRATEGY
# =============================================================================

class InventoryFadingStrategy:
    """
    Fade market makers when they have extreme inventory positions.

    Theory: MMs need to maintain neutral inventory. When they accumulate
    too much of one side, they adjust quotes to encourage offsetting flow,
    creating predictable price movements.

    Strategy:
    1. Estimate MM inventory from order flow
    2. Detect extreme positions
    3. Trade in direction of expected inventory reversion
    4. Time entry for optimal fill
    """

    def __init__(
        self,
        inventory_zscore_threshold: float = 2.0,
        min_confidence: float = 0.6,
        max_position_pct: float = 0.1,
        reversion_lookback: int = 500
    ):
        self.inventory_zscore_threshold = inventory_zscore_threshold
        self.min_confidence = min_confidence
        self.max_position_pct = max_position_pct
        self.reversion_lookback = reversion_lookback

        # State tracking
        self._inventory_history: Dict[str, deque] = {}
        self._price_history: Dict[str, deque] = {}
        self._reversion_outcomes: Dict[str, deque] = {}

        # Calibration
        self._reversion_success_rate: Dict[str, float] = {}
        self._avg_reversion_time: Dict[str, float] = {}
        self._avg_reversion_magnitude: Dict[str, float] = {}

    def update(
        self,
        venue: str,
        market: str,
        inventory_estimate: float,
        mid_price: float,
        spread: float
    ):
        """Update strategy with new data"""
        key = f"{venue}_{market}"

        if key not in self._inventory_history:
            self._inventory_history[key] = deque(maxlen=self.reversion_lookback)
            self._price_history[key] = deque(maxlen=self.reversion_lookback)
            self._reversion_outcomes[key] = deque(maxlen=100)

        self._inventory_history[key].append({
            "inventory": inventory_estimate,
            "timestamp": time.time()
        })

        self._price_history[key].append({
            "mid_price": mid_price,
            "spread": spread,
            "timestamp": time.time()
        })

        # Check for reversion completion on past signals
        self._check_reversion_outcomes(key, mid_price)

    def get_fade_signal(
        self,
        venue: str,
        market: str,
        current_price: float,
        current_spread: float
    ) -> InventoryFadeSignal:
        """Generate fade signal based on inventory analysis"""
        key = f"{venue}_{market}"

        # Default neutral signal
        neutral_signal = InventoryFadeSignal(
            direction="neutral",
            strength=FadeSignalStrength.NONE,
            confidence=0.0,
            mm_inventory_estimate=0.0,
            mm_inventory_zscore=0.0,
            inventory_reversion_probability=0.0,
            optimal_entry_delay_ms=0.0,
            expected_reversion_time_ms=0.0,
            risk_score=0.5,
            max_position_pct=0.0,
            entry_price=current_price,
            target_price=current_price,
            stop_loss=current_price,
            expected_profit_bps=0.0
        )

        if key not in self._inventory_history or len(self._inventory_history[key]) < 50:
            return neutral_signal

        # Calculate inventory statistics
        inventory_data = [d["inventory"] for d in self._inventory_history[key]]
        current_inventory = inventory_data[-1]

        mean_inventory = np.mean(inventory_data)
        std_inventory = np.std(inventory_data)

        if std_inventory < 1e-10:
            return neutral_signal

        # Calculate z-score
        inventory_zscore = (current_inventory - mean_inventory) / std_inventory

        # Check if extreme enough to fade
        if abs(inventory_zscore) < self.inventory_zscore_threshold:
            return neutral_signal

        # Determine fade direction (opposite of inventory)
        direction = "sell" if inventory_zscore > 0 else "buy"

        # Calculate signal strength
        strength = self._calculate_signal_strength(inventory_zscore)

        # Calculate reversion probability
        reversion_prob = self._estimate_reversion_probability(key, inventory_zscore)

        # Calculate confidence
        confidence = self._calculate_confidence(key, inventory_zscore, reversion_prob)

        if confidence < self.min_confidence:
            return neutral_signal

        # Calculate timing
        optimal_delay, expected_reversion_time = self._calculate_timing(key, inventory_zscore)

        # Calculate risk
        risk_score = self._calculate_risk_score(key, inventory_zscore, current_spread)

        # Calculate price targets
        entry_price, target_price, stop_loss, expected_profit_bps = self._calculate_price_targets(
            key, direction, current_price, current_spread, inventory_zscore
        )

        # Calculate position sizing
        max_position = self._calculate_max_position(confidence, risk_score)

        return InventoryFadeSignal(
            direction=direction,
            strength=strength,
            confidence=confidence,
            mm_inventory_estimate=current_inventory,
            mm_inventory_zscore=inventory_zscore,
            inventory_reversion_probability=reversion_prob,
            optimal_entry_delay_ms=optimal_delay,
            expected_reversion_time_ms=expected_reversion_time,
            risk_score=risk_score,
            max_position_pct=max_position,
            entry_price=entry_price,
            target_price=target_price,
            stop_loss=stop_loss,
            expected_profit_bps=expected_profit_bps
        )

    def _calculate_signal_strength(self, zscore: float) -> FadeSignalStrength:
        """Map z-score to signal strength"""
        abs_z = abs(zscore)

        if abs_z < 2.0:
            return FadeSignalStrength.NONE
        elif abs_z < 2.5:
            return FadeSignalStrength.WEAK
        elif abs_z < 3.0:
            return FadeSignalStrength.MODERATE
        elif abs_z < 3.5:
            return FadeSignalStrength.STRONG
        else:
            return FadeSignalStrength.VERY_STRONG

    def _estimate_reversion_probability(self, key: str, zscore: float) -> float:
        """Estimate probability of inventory reversion"""
        # Base probability from z-score
        # Higher z-score = higher reversion probability
        base_prob = 1 - 1 / (1 + np.exp(abs(zscore) - 2))  # Sigmoid centered at 2

        # Adjust based on historical success rate
        if key in self._reversion_success_rate:
            historical_rate = self._reversion_success_rate[key]
            # Weighted average: 70% base, 30% historical
            return 0.7 * base_prob + 0.3 * historical_rate

        return base_prob

    def _calculate_confidence(
        self,
        key: str,
        zscore: float,
        reversion_prob: float
    ) -> float:
        """Calculate overall confidence in signal"""
        # Base confidence from z-score certainty
        zscore_confidence = min(1.0, abs(zscore) / 4.0)

        # Adjust for sample size
        sample_size = len(self._inventory_history.get(key, []))
        sample_confidence = min(1.0, sample_size / 200)

        # Combine factors
        confidence = (
            0.4 * zscore_confidence +
            0.3 * reversion_prob +
            0.3 * sample_confidence
        )

        return min(0.95, confidence)

    def _calculate_timing(
        self,
        key: str,
        zscore: float
    ) -> Tuple[float, float]:
        """Calculate optimal entry timing"""
        # Base timing based on z-score magnitude
        # More extreme = faster reversion expected
        base_reversion_ms = 5000 / abs(zscore)  # Higher z-score = faster

        # Optimal entry delay
        # Enter slightly before expected reversion peak
        optimal_delay_ms = base_reversion_ms * 0.2

        # Adjust based on historical data
        if key in self._avg_reversion_time:
            historical_time = self._avg_reversion_time[key]
            expected_reversion_ms = 0.7 * base_reversion_ms + 0.3 * historical_time
        else:
            expected_reversion_ms = base_reversion_ms

        return optimal_delay_ms, expected_reversion_ms

    def _calculate_risk_score(
        self,
        key: str,
        zscore: float,
        spread: float
    ) -> float:
        """Calculate risk score for the trade"""
        risk = 0.0

        # Risk from uncertainty (lower z-score = higher uncertainty risk)
        uncertainty_risk = max(0, 1 - abs(zscore) / 4)
        risk += 0.3 * uncertainty_risk

        # Risk from wide spread
        spread_risk = min(1.0, spread * 100)  # Assuming spread in decimal
        risk += 0.2 * spread_risk

        # Risk from short history
        history_len = len(self._inventory_history.get(key, []))
        history_risk = max(0, 1 - history_len / 200)
        risk += 0.2 * history_risk

        # Risk from poor historical performance
        if key in self._reversion_success_rate:
            failure_rate = 1 - self._reversion_success_rate[key]
            risk += 0.3 * failure_rate
        else:
            risk += 0.15  # Unknown performance

        return min(1.0, risk)

    def _calculate_price_targets(
        self,
        key: str,
        direction: str,
        current_price: float,
        spread: float,
        zscore: float
    ) -> Tuple[float, float, float, float]:
        """Calculate entry, target, and stop-loss prices"""
        # Expected price movement from reversion
        # More extreme inventory = larger expected move
        expected_move_bps = 5 * abs(zscore)  # 5 bps per z-score unit

        # Adjust based on historical magnitude
        if key in self._avg_reversion_magnitude:
            historical_move = self._avg_reversion_magnitude[key]
            expected_move_bps = 0.6 * expected_move_bps + 0.4 * historical_move

        expected_move = current_price * expected_move_bps / 10000

        if direction == "buy":
            # Buying: enter at current, target higher, stop lower
            entry_price = current_price
            target_price = current_price + expected_move
            stop_loss = current_price - expected_move * 0.5
        else:
            # Selling: enter at current, target lower, stop higher
            entry_price = current_price
            target_price = current_price - expected_move
            stop_loss = current_price + expected_move * 0.5

        # Account for spread in profit calculation
        spread_cost_bps = spread / current_price * 10000
        net_profit_bps = expected_move_bps - spread_cost_bps

        return entry_price, target_price, stop_loss, max(0, net_profit_bps)

    def _calculate_max_position(
        self,
        confidence: float,
        risk_score: float
    ) -> float:
        """Calculate maximum position as percentage of liquidity"""
        # Higher confidence and lower risk = larger position
        base_position = self.max_position_pct

        # Scale by confidence
        position = base_position * confidence

        # Reduce for high risk
        position *= (1 - 0.5 * risk_score)

        return max(0.01, min(self.max_position_pct, position))

    def _check_reversion_outcomes(self, key: str, current_price: float):
        """Check if past signals resulted in successful reversions"""
        # This would track actual outcomes to calibrate the strategy
        # Simplified implementation - in production would track actual trades
        pass

    def record_outcome(
        self,
        venue: str,
        market: str,
        signal_timestamp: float,
        entry_price: float,
        exit_price: float,
        direction: str,
        duration_ms: float
    ):
        """Record outcome of a fade trade for calibration"""
        key = f"{venue}_{market}"

        if key not in self._reversion_outcomes:
            self._reversion_outcomes[key] = deque(maxlen=100)

        # Calculate if successful
        if direction == "buy":
            success = exit_price > entry_price
            magnitude_bps = (exit_price - entry_price) / entry_price * 10000
        else:
            success = exit_price < entry_price
            magnitude_bps = (entry_price - exit_price) / entry_price * 10000

        self._reversion_outcomes[key].append({
            "success": success,
            "magnitude_bps": magnitude_bps,
            "duration_ms": duration_ms,
            "timestamp": time.time()
        })

        # Update calibration
        outcomes = list(self._reversion_outcomes[key])
        self._reversion_success_rate[key] = np.mean([o["success"] for o in outcomes])
        self._avg_reversion_time[key] = np.mean([o["duration_ms"] for o in outcomes])
        self._avg_reversion_magnitude[key] = np.mean([o["magnitude_bps"] for o in outcomes])


# =============================================================================
# SPREAD REGIME DETECTION
# =============================================================================

class SpreadRegimeDetector:
    """
    Detect and classify spread regimes for optimal trade timing.

    Features:
    - Regime classification (tight, normal, wide, etc.)
    - Regime transition prediction
    - Optimal entry timing signals
    - Spread volatility analysis
    """

    def __init__(
        self,
        history_size: int = 1000,
        regime_lookback: int = 100
    ):
        self.history_size = history_size
        self.regime_lookback = regime_lookback

        # Spread history
        self._spread_history: Dict[str, deque] = {}
        self._regime_history: Dict[str, deque] = {}

        # Regime transition tracking
        self._transition_matrix: Dict[str, Dict[str, Dict[str, int]]] = {}
        self._current_regime: Dict[str, SpreadRegime] = {}
        self._regime_start_time: Dict[str, float] = {}

        # Regime thresholds in basis points
        self._regime_thresholds = {
            SpreadRegime.ULTRA_TIGHT: (0, 1),
            SpreadRegime.TIGHT: (1, 3),
            SpreadRegime.NORMAL: (3, 10),
            SpreadRegime.WIDE: (10, 25),
            SpreadRegime.VERY_WIDE: (25, 50),
            SpreadRegime.EXTREME: (50, float('inf'))
        }

    def update(
        self,
        venue: str,
        market: str,
        spread: float,
        mid_price: float
    ):
        """Update detector with new spread observation"""
        key = f"{venue}_{market}"

        if key not in self._spread_history:
            self._spread_history[key] = deque(maxlen=self.history_size)
            self._regime_history[key] = deque(maxlen=self.history_size)
            self._transition_matrix[key] = {r.value: {rr.value: 0 for rr in SpreadRegime} for r in SpreadRegime}

        # Calculate spread in basis points
        spread_bps = (spread / mid_price) * 10000 if mid_price > 0 else 0

        self._spread_history[key].append({
            "spread_bps": spread_bps,
            "spread": spread,
            "mid_price": mid_price,
            "timestamp": time.time()
        })

        # Classify regime
        new_regime = self._classify_regime(spread_bps)

        # Track regime transitions
        if key in self._current_regime:
            old_regime = self._current_regime[key]
            if old_regime != new_regime:
                # Regime change detected
                self._transition_matrix[key][old_regime.value][new_regime.value] += 1
                self._regime_start_time[key] = time.time()

                logger.info(
                    f"Spread regime change: {old_regime.value} -> {new_regime.value} "
                    f"({key})"
                )
        else:
            self._regime_start_time[key] = time.time()

        self._current_regime[key] = new_regime
        self._regime_history[key].append({
            "regime": new_regime,
            "timestamp": time.time()
        })

    def get_regime_analysis(
        self,
        venue: str,
        market: str
    ) -> SpreadRegimeAnalysis:
        """Get comprehensive spread regime analysis"""
        key = f"{venue}_{market}"

        # Default analysis
        default_analysis = SpreadRegimeAnalysis(
            current_regime=SpreadRegime.NORMAL,
            regime_confidence=0.0,
            regime_duration_seconds=0.0,
            current_spread_bps=0.0,
            avg_spread_bps=0.0,
            spread_volatility=0.0,
            spread_percentile=50.0,
            tightening_probability=0.33,
            widening_probability=0.33,
            stable_probability=0.34,
            is_optimal_entry=False,
            entry_score=0.5,
            wait_for_tightening=False,
            expected_wait_ms=0.0,
            avg_regime_duration_seconds=0.0,
            regime_transition_rate=0.0
        )

        if key not in self._spread_history or len(self._spread_history[key]) < 20:
            return default_analysis

        spread_data = list(self._spread_history[key])
        current_spread_bps = spread_data[-1]["spread_bps"]
        current_regime = self._current_regime.get(key, SpreadRegime.NORMAL)

        # Calculate spread statistics
        spreads_bps = [d["spread_bps"] for d in spread_data]
        avg_spread_bps = np.mean(spreads_bps)
        spread_volatility = np.std(spreads_bps)
        spread_percentile = np.searchsorted(sorted(spreads_bps), current_spread_bps) / len(spreads_bps) * 100

        # Calculate regime duration
        regime_start = self._regime_start_time.get(key, time.time())
        regime_duration = time.time() - regime_start

        # Calculate regime confidence
        regime_confidence = self._calculate_regime_confidence(key, current_regime)

        # Calculate transition probabilities
        tightening_prob, widening_prob, stable_prob = self._calculate_transition_probs(
            key, current_regime
        )

        # Calculate entry score
        entry_score, is_optimal, wait_for_tightening, expected_wait = self._calculate_entry_timing(
            key, current_spread_bps, avg_spread_bps, spread_percentile, tightening_prob
        )

        # Calculate historical regime stats
        avg_duration, transition_rate = self._calculate_regime_stats(key)

        return SpreadRegimeAnalysis(
            current_regime=current_regime,
            regime_confidence=regime_confidence,
            regime_duration_seconds=regime_duration,
            current_spread_bps=current_spread_bps,
            avg_spread_bps=avg_spread_bps,
            spread_volatility=spread_volatility,
            spread_percentile=spread_percentile,
            tightening_probability=tightening_prob,
            widening_probability=widening_prob,
            stable_probability=stable_prob,
            is_optimal_entry=is_optimal,
            entry_score=entry_score,
            wait_for_tightening=wait_for_tightening,
            expected_wait_ms=expected_wait,
            avg_regime_duration_seconds=avg_duration,
            regime_transition_rate=transition_rate
        )

    def _classify_regime(self, spread_bps: float) -> SpreadRegime:
        """Classify spread into regime category"""
        for regime, (low, high) in self._regime_thresholds.items():
            if low <= spread_bps < high:
                return regime
        return SpreadRegime.EXTREME

    def _calculate_regime_confidence(
        self,
        key: str,
        current_regime: SpreadRegime
    ) -> float:
        """Calculate confidence in current regime classification"""
        if key not in self._spread_history:
            return 0.0

        spread_data = list(self._spread_history[key])[-self.regime_lookback:]

        if len(spread_data) < 10:
            return 0.3

        # Count how many recent observations match current regime
        regime_matches = sum(
            1 for d in spread_data
            if self._classify_regime(d["spread_bps"]) == current_regime
        )

        match_rate = regime_matches / len(spread_data)

        # Adjust for regime duration
        duration = time.time() - self._regime_start_time.get(key, time.time())
        duration_factor = min(1.0, duration / 60)  # Max confidence after 1 minute

        return min(0.95, 0.5 * match_rate + 0.5 * duration_factor)

    def _calculate_transition_probs(
        self,
        key: str,
        current_regime: SpreadRegime
    ) -> Tuple[float, float, float]:
        """Calculate regime transition probabilities"""
        if key not in self._transition_matrix:
            return 0.33, 0.33, 0.34

        transitions = self._transition_matrix[key][current_regime.value]
        total_transitions = sum(transitions.values())

        if total_transitions < 10:
            # Not enough data, use priors
            return 0.33, 0.33, 0.34

        # Define tightening/widening regimes
        regime_order = [
            SpreadRegime.ULTRA_TIGHT, SpreadRegime.TIGHT, SpreadRegime.NORMAL,
            SpreadRegime.WIDE, SpreadRegime.VERY_WIDE, SpreadRegime.EXTREME
        ]
        current_idx = regime_order.index(current_regime)

        tightening_count = 0
        widening_count = 0
        stable_count = transitions[current_regime.value]

        for regime, count in transitions.items():
            if regime == current_regime.value:
                continue
            target_idx = regime_order.index(SpreadRegime(regime))
            if target_idx < current_idx:
                tightening_count += count
            else:
                widening_count += count

        total = tightening_count + widening_count + stable_count
        if total == 0:
            return 0.33, 0.33, 0.34

        return (
            tightening_count / total,
            widening_count / total,
            stable_count / total
        )

    def _calculate_entry_timing(
        self,
        key: str,
        current_spread_bps: float,
        avg_spread_bps: float,
        spread_percentile: float,
        tightening_prob: float
    ) -> Tuple[float, bool, bool, float]:
        """Calculate optimal entry timing"""
        # Entry score based on spread relative to average
        spread_ratio = current_spread_bps / avg_spread_bps if avg_spread_bps > 0 else 1

        # Lower spread = better entry (inverted score)
        spread_score = max(0, 1 - (spread_ratio - 0.5))

        # Percentile score (lower percentile = better)
        percentile_score = 1 - spread_percentile / 100

        # Combine scores
        entry_score = 0.6 * spread_score + 0.4 * percentile_score

        # Determine if optimal
        is_optimal = (
            entry_score > 0.6 and
            spread_percentile < 30
        )

        # Should we wait for tightening?
        wait_for_tightening = (
            not is_optimal and
            tightening_prob > 0.4 and
            spread_percentile > 50
        )

        # Expected wait time (rough estimate)
        if wait_for_tightening:
            # Estimate based on historical regime duration
            expected_wait = 5000 * (spread_percentile / 100)  # ms
        else:
            expected_wait = 0

        return entry_score, is_optimal, wait_for_tightening, expected_wait

    def _calculate_regime_stats(self, key: str) -> Tuple[float, float]:
        """Calculate historical regime statistics"""
        if key not in self._regime_history:
            return 0.0, 0.0

        regime_data = list(self._regime_history[key])

        if len(regime_data) < 20:
            return 0.0, 0.0

        # Calculate regime durations
        durations = []
        current_regime = None
        regime_start = None

        for entry in regime_data:
            if entry["regime"] != current_regime:
                if current_regime is not None and regime_start is not None:
                    durations.append(entry["timestamp"] - regime_start)
                current_regime = entry["regime"]
                regime_start = entry["timestamp"]

        avg_duration = np.mean(durations) if durations else 0

        # Transition rate (per hour)
        total_time = regime_data[-1]["timestamp"] - regime_data[0]["timestamp"]
        transition_rate = len(durations) / (total_time / 3600) if total_time > 0 else 0

        return avg_duration, transition_rate

    def get_entry_recommendation(
        self,
        venue: str,
        market: str,
        urgency: float = 0.5
    ) -> Dict:
        """Get entry timing recommendation"""
        analysis = self.get_regime_analysis(venue, market)

        # Adjust recommendation based on urgency
        if urgency > 0.8:
            # High urgency - enter now regardless of spread
            return {
                "action": "enter_now",
                "reason": "High urgency override",
                "entry_score": analysis.entry_score,
                "spread_cost_bps": analysis.current_spread_bps
            }

        if analysis.is_optimal_entry:
            return {
                "action": "enter_now",
                "reason": "Optimal spread conditions",
                "entry_score": analysis.entry_score,
                "spread_cost_bps": analysis.current_spread_bps
            }

        if analysis.wait_for_tightening and urgency < 0.5:
            return {
                "action": "wait",
                "reason": "Spread likely to tighten",
                "expected_wait_ms": analysis.expected_wait_ms,
                "tightening_probability": analysis.tightening_probability,
                "current_spread_bps": analysis.current_spread_bps
            }

        # Default to cautious entry with small size
        return {
            "action": "enter_partial",
            "reason": "Suboptimal spread, partial entry",
            "entry_score": analysis.entry_score,
            "suggested_fill_pct": max(0.3, analysis.entry_score),
            "spread_cost_bps": analysis.current_spread_bps
        }


# =============================================================================
# QUOTE STUFFING DETECTION
# =============================================================================

class QuoteStuffingDetector:
    """
    Detect quote stuffing, spoofing, and other manipulative behaviors.

    Detection methods:
    1. Quote rate analysis (excessive updates)
    2. Cancel rate analysis (high cancel-to-trade ratio)
    3. Layering detection (multiple fake levels)
    4. Flickering detection (rapid on/off quotes)
    5. Momentum ignition patterns
    """

    def __init__(
        self,
        quote_window_ms: float = 1000,
        max_quote_rate: float = 100,          # Max quotes per second
        max_cancel_rate: float = 50,          # Max cancels per second
        max_quote_trade_ratio: float = 100,   # Max quotes per trade
        layering_threshold: int = 5,          # Min levels for layering
        flicker_threshold_ms: float = 50      # Quotes lasting < this are flickering
    ):
        self.quote_window_ms = quote_window_ms
        self.max_quote_rate = max_quote_rate
        self.max_cancel_rate = max_cancel_rate
        self.max_quote_trade_ratio = max_quote_trade_ratio
        self.layering_threshold = layering_threshold
        self.flicker_threshold_ms = flicker_threshold_ms

        # Event tracking
        self._quote_events: Dict[str, deque] = {}
        self._trade_events: Dict[str, deque] = {}
        self._quote_lifetimes: Dict[str, deque] = {}  # Track how long quotes last

        # Alert tracking
        self._active_alerts: Dict[str, QuoteStuffingAlert] = {}
        self._alert_history: Dict[str, deque] = {}

    def record_quote_event(
        self,
        venue: str,
        market: str,
        price: float,
        quantity: float,
        side: str,
        event_type: str,  # "add", "modify", "cancel"
        level: int = 0
    ):
        """Record a quote event for analysis"""
        key = f"{venue}_{market}"

        if key not in self._quote_events:
            self._quote_events[key] = deque(maxlen=10000)
            self._quote_lifetimes[key] = deque(maxlen=10000)

        event = QuoteEvent(
            price=price,
            quantity=quantity,
            side=side,
            event_type=event_type,
            timestamp=time.time(),
            level=level
        )

        self._quote_events[key].append(event)

        # Track quote lifetime for flickering detection
        if event_type == "cancel":
            self._track_quote_lifetime(key, price, side)

    def record_trade_event(
        self,
        venue: str,
        market: str,
        price: float,
        quantity: float,
        side: str
    ):
        """Record a trade event for quote-to-trade ratio"""
        key = f"{venue}_{market}"

        if key not in self._trade_events:
            self._trade_events[key] = deque(maxlen=10000)

        event = TradeEvent(
            price=price,
            quantity=quantity,
            side=side,
            timestamp=time.time()
        )

        self._trade_events[key].append(event)

    def _track_quote_lifetime(self, key: str, price: float, side: str):
        """Track how long a quote was live before cancellation"""
        quote_events = list(self._quote_events[key])

        # Find the add event for this price/side
        for i in range(len(quote_events) - 2, -1, -1):
            event = quote_events[i]
            if (event.price == price and
                event.side == side and
                event.event_type == "add"):
                lifetime_ms = (time.time() - event.timestamp) * 1000
                self._quote_lifetimes[key].append({
                    "price": price,
                    "side": side,
                    "lifetime_ms": lifetime_ms,
                    "timestamp": time.time()
                })
                break

    def detect_stuffing(
        self,
        venue: str,
        market: str
    ) -> QuoteStuffingAlert:
        """Analyze for quote stuffing patterns"""
        key = f"{venue}_{market}"

        # Default no-alert result
        no_alert = QuoteStuffingAlert(
            stuffing_type=QuoteStuffingType.NONE,
            confidence=0.0,
            severity=0.0,
            quote_rate_per_second=0.0,
            cancel_rate_per_second=0.0,
            quote_to_trade_ratio=0.0,
            affected_price_levels=[],
            fake_liquidity_estimate=0.0,
            should_pause_trading=False,
            reduce_aggression=False,
            ignore_levels=[],
            likely_source="none"
        )

        if key not in self._quote_events or len(self._quote_events[key]) < 10:
            return no_alert

        # Get recent events
        now = time.time()
        window_seconds = self.quote_window_ms / 1000

        recent_quotes = [
            e for e in self._quote_events[key]
            if now - e.timestamp <= window_seconds
        ]

        recent_trades = [
            e for e in self._trade_events.get(key, [])
            if now - e.timestamp <= window_seconds
        ]

        if len(recent_quotes) < 5:
            return no_alert

        # Calculate rates
        quote_rate = len(recent_quotes) / window_seconds
        cancel_count = sum(1 for e in recent_quotes if e.event_type == "cancel")
        cancel_rate = cancel_count / window_seconds

        trade_count = max(1, len(recent_trades))
        quote_trade_ratio = len(recent_quotes) / trade_count

        # Run detection algorithms
        detections = []

        # 1. High quote rate detection
        if quote_rate > self.max_quote_rate:
            detections.append({
                "type": QuoteStuffingType.SPOOFING,
                "confidence": min(1.0, quote_rate / (self.max_quote_rate * 2)),
                "severity": min(1.0, (quote_rate - self.max_quote_rate) / self.max_quote_rate)
            })

        # 2. High cancel rate detection
        if cancel_rate > self.max_cancel_rate:
            detections.append({
                "type": QuoteStuffingType.FLICKERING,
                "confidence": min(1.0, cancel_rate / (self.max_cancel_rate * 2)),
                "severity": min(1.0, (cancel_rate - self.max_cancel_rate) / self.max_cancel_rate)
            })

        # 3. Quote-to-trade ratio
        if quote_trade_ratio > self.max_quote_trade_ratio:
            detections.append({
                "type": QuoteStuffingType.SPOOFING,
                "confidence": min(1.0, quote_trade_ratio / (self.max_quote_trade_ratio * 2)),
                "severity": min(1.0, (quote_trade_ratio - self.max_quote_trade_ratio) / self.max_quote_trade_ratio)
            })

        # 4. Layering detection
        layering_result = self._detect_layering(key, recent_quotes)
        if layering_result:
            detections.append(layering_result)

        # 5. Flickering detection
        flickering_result = self._detect_flickering(key)
        if flickering_result:
            detections.append(flickering_result)

        # 6. Momentum ignition detection
        momentum_result = self._detect_momentum_ignition(key, recent_quotes, recent_trades)
        if momentum_result:
            detections.append(momentum_result)

        if not detections:
            return no_alert

        # Return most severe detection
        most_severe = max(detections, key=lambda x: x["severity"])

        # Identify affected price levels
        affected_levels = self._get_affected_levels(recent_quotes)

        # Estimate fake liquidity
        fake_liquidity = self._estimate_fake_liquidity(key, recent_quotes)

        # Determine recommendations
        severity = most_severe["severity"]
        should_pause = severity > 0.8
        reduce_aggression = severity > 0.5

        alert = QuoteStuffingAlert(
            stuffing_type=most_severe["type"],
            confidence=most_severe["confidence"],
            severity=severity,
            quote_rate_per_second=quote_rate,
            cancel_rate_per_second=cancel_rate,
            quote_to_trade_ratio=quote_trade_ratio,
            affected_price_levels=affected_levels,
            fake_liquidity_estimate=fake_liquidity,
            should_pause_trading=should_pause,
            reduce_aggression=reduce_aggression,
            ignore_levels=affected_levels[:3] if reduce_aggression else [],
            likely_source=self._identify_source(recent_quotes)
        )

        # Store alert
        self._active_alerts[key] = alert
        if key not in self._alert_history:
            self._alert_history[key] = deque(maxlen=1000)
        self._alert_history[key].append(alert)

        logger.warning(
            f"Quote stuffing detected: {alert.stuffing_type.value} "
            f"(severity: {alert.severity:.2f}, venue: {venue}, market: {market})"
        )

        return alert

    def _detect_layering(
        self,
        key: str,
        recent_quotes: List[QuoteEvent]
    ) -> Optional[Dict]:
        """Detect layering (multiple fake levels on one side)"""
        # Group quotes by side and level
        bid_levels = set()
        ask_levels = set()

        for quote in recent_quotes:
            if quote.event_type in ["add", "modify"]:
                if quote.side == "bid":
                    bid_levels.add(quote.level)
                else:
                    ask_levels.add(quote.level)

        # Check for excessive levels on one side
        bid_count = len(bid_levels)
        ask_count = len(ask_levels)

        if max(bid_count, ask_count) >= self.layering_threshold:
            # Check for imbalance (layering typically on one side)
            if bid_count > ask_count * 2 or ask_count > bid_count * 2:
                return {
                    "type": QuoteStuffingType.LAYERING,
                    "confidence": min(1.0, max(bid_count, ask_count) / (self.layering_threshold * 2)),
                    "severity": min(1.0, abs(bid_count - ask_count) / 10)
                }

        return None

    def _detect_flickering(self, key: str) -> Optional[Dict]:
        """Detect flickering (rapid add/cancel of quotes)"""
        if key not in self._quote_lifetimes:
            return None

        recent_lifetimes = [
            l for l in self._quote_lifetimes[key]
            if time.time() - l["timestamp"] <= 1.0  # Last second
        ]

        if len(recent_lifetimes) < 5:
            return None

        # Count short-lived quotes
        short_lived = sum(
            1 for l in recent_lifetimes
            if l["lifetime_ms"] < self.flicker_threshold_ms
        )

        flicker_rate = short_lived / len(recent_lifetimes)

        if flicker_rate > 0.3:  # More than 30% are flickering
            return {
                "type": QuoteStuffingType.FLICKERING,
                "confidence": min(1.0, flicker_rate),
                "severity": min(1.0, flicker_rate * 1.5)
            }

        return None

    def _detect_momentum_ignition(
        self,
        key: str,
        recent_quotes: List[QuoteEvent],
        recent_trades: List[TradeEvent]
    ) -> Optional[Dict]:
        """Detect momentum ignition patterns"""
        if len(recent_quotes) < 20 or len(recent_trades) < 5:
            return None

        # Look for pattern: aggressive quotes followed by trades in same direction
        # followed by rapid quote cancellation

        # Group quotes by time bucket
        buckets = {}
        for quote in recent_quotes:
            bucket = int(quote.timestamp * 10)  # 100ms buckets
            if bucket not in buckets:
                buckets[bucket] = {"adds": 0, "cancels": 0, "side": None}
            if quote.event_type == "add":
                buckets[bucket]["adds"] += 1
                buckets[bucket]["side"] = quote.side
            elif quote.event_type == "cancel":
                buckets[bucket]["cancels"] += 1

        # Look for burst of adds followed by burst of cancels
        bucket_list = sorted(buckets.items())

        for i in range(len(bucket_list) - 2):
            b1, b2, b3 = bucket_list[i:i+3]

            # Pattern: many adds, few activity, many cancels
            if (b1[1]["adds"] > 10 and
                b3[1]["cancels"] > 10 and
                b1[1]["adds"] > b1[1]["cancels"] * 3):
                return {
                    "type": QuoteStuffingType.MOMENTUM_IGNITION,
                    "confidence": 0.7,
                    "severity": 0.8
                }

        return None

    def _get_affected_levels(self, quotes: List[QuoteEvent]) -> List[float]:
        """Get price levels affected by stuffing"""
        # Count activity per price level
        level_activity = {}
        for quote in quotes:
            if quote.price not in level_activity:
                level_activity[quote.price] = 0
            level_activity[quote.price] += 1

        # Sort by activity and return top levels
        sorted_levels = sorted(
            level_activity.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return [price for price, _ in sorted_levels[:10]]

    def _estimate_fake_liquidity(
        self,
        key: str,
        recent_quotes: List[QuoteEvent]
    ) -> float:
        """Estimate the amount of fake liquidity"""
        # Sum quantity of cancelled quotes
        fake_volume = sum(
            quote.quantity for quote in recent_quotes
            if quote.event_type == "cancel"
        )

        return fake_volume

    def _identify_source(self, quotes: List[QuoteEvent]) -> str:
        """Try to identify the source of stuffing"""
        # Simplified - would use more sophisticated analysis in production

        # Check for MM-like patterns
        add_count = sum(1 for q in quotes if q.event_type == "add")
        cancel_count = sum(1 for q in quotes if q.event_type == "cancel")

        if cancel_count > add_count * 0.8:
            return "algo"  # High cancel rate suggests algo
        elif add_count > 50:
            return "mm"  # High quote rate might be MM

        return "unknown"

    def get_current_alert(
        self,
        venue: str,
        market: str
    ) -> Optional[QuoteStuffingAlert]:
        """Get current active alert if any"""
        key = f"{venue}_{market}"

        alert = self._active_alerts.get(key)

        if alert is None:
            return None

        # Check if alert is still fresh (within last 5 seconds)
        if time.time() - alert.timestamp > 5:
            return None

        return alert

    def should_trade(
        self,
        venue: str,
        market: str
    ) -> Tuple[bool, str]:
        """Determine if it's safe to trade given stuffing analysis"""
        alert = self.get_current_alert(venue, market)

        if alert is None:
            return True, "No quote stuffing detected"

        if alert.should_pause_trading:
            return False, f"Quote stuffing detected: {alert.stuffing_type.value} (severity: {alert.severity:.2f})"

        if alert.reduce_aggression:
            return True, f"Caution: {alert.stuffing_type.value} detected, reduce size"

        return True, "Safe to trade"

    def get_adjusted_book(
        self,
        venue: str,
        market: str,
        bids: List[Dict],
        asks: List[Dict]
    ) -> Tuple[List[Dict], List[Dict]]:
        """Return order book with suspected fake liquidity removed"""
        alert = self.get_current_alert(venue, market)

        if alert is None or not alert.ignore_levels:
            return bids, asks

        ignore_set = set(alert.ignore_levels)

        filtered_bids = [b for b in bids if b["price"] not in ignore_set]
        filtered_asks = [a for a in asks if a["price"] not in ignore_set]

        return filtered_bids, filtered_asks


# =============================================================================
# INTEGRATED MM EXPLOITATION ENGINE
# =============================================================================

class MMExploitationEngine:
    """
    Integrated engine combining all MM exploitation strategies.

    Provides unified interface for:
    - Inventory-based fading
    - Spread regime analysis
    - Quote stuffing detection
    """

    def __init__(self):
        self.inventory_fading = InventoryFadingStrategy()
        self.spread_regime = SpreadRegimeDetector()
        self.quote_stuffing = QuoteStuffingDetector()

        # Tracking
        self._last_analysis: Dict[str, Dict] = {}

    def update(
        self,
        venue: str,
        market: str,
        inventory_estimate: float,
        mid_price: float,
        spread: float,
        bids: Optional[List[Dict]] = None,
        asks: Optional[List[Dict]] = None
    ):
        """Update all strategies with new market data"""
        # Update inventory fading
        self.inventory_fading.update(
            venue, market, inventory_estimate, mid_price, spread
        )

        # Update spread regime
        self.spread_regime.update(venue, market, spread, mid_price)

        # Update quote stuffing with order book changes if provided
        if bids and asks:
            # Record top-of-book quote events
            key = f"{venue}_{market}"

            for i, bid in enumerate(bids[:5]):
                self.quote_stuffing.record_quote_event(
                    venue, market, bid["price"], bid["quantity"],
                    "bid", "add", level=i
                )

            for i, ask in enumerate(asks[:5]):
                self.quote_stuffing.record_quote_event(
                    venue, market, ask["price"], ask["quantity"],
                    "ask", "add", level=i
                )

    def record_trade(
        self,
        venue: str,
        market: str,
        price: float,
        quantity: float,
        side: str
    ):
        """Record a trade for quote-to-trade ratio analysis"""
        self.quote_stuffing.record_trade_event(
            venue, market, price, quantity, side
        )

    def get_comprehensive_analysis(
        self,
        venue: str,
        market: str,
        current_price: float,
        current_spread: float
    ) -> Dict:
        """Get comprehensive MM exploitation analysis"""
        key = f"{venue}_{market}"

        # Get individual analyses
        fade_signal = self.inventory_fading.get_fade_signal(
            venue, market, current_price, current_spread
        )

        spread_analysis = self.spread_regime.get_regime_analysis(venue, market)

        stuffing_alert = self.quote_stuffing.detect_stuffing(venue, market)

        # Combine into unified recommendation
        recommendation = self._generate_recommendation(
            fade_signal, spread_analysis, stuffing_alert
        )

        analysis = {
            "venue": venue,
            "market": market,
            "timestamp": time.time(),
            "fade_signal": fade_signal.to_dict(),
            "spread_analysis": spread_analysis.to_dict(),
            "stuffing_alert": stuffing_alert.to_dict() if stuffing_alert.stuffing_type != QuoteStuffingType.NONE else None,
            "recommendation": recommendation
        }

        self._last_analysis[key] = analysis

        return analysis

    def _generate_recommendation(
        self,
        fade: InventoryFadeSignal,
        spread: SpreadRegimeAnalysis,
        stuffing: QuoteStuffingAlert
    ) -> Dict:
        """Generate unified trading recommendation"""
        # Start with base recommendation
        action = "hold"
        direction = "neutral"
        confidence = 0.0
        size_multiplier = 1.0
        reasons = []
        warnings = []

        # Check for quote stuffing (takes priority)
        if stuffing.stuffing_type != QuoteStuffingType.NONE:
            if stuffing.should_pause_trading:
                return {
                    "action": "pause",
                    "direction": "neutral",
                    "confidence": stuffing.confidence,
                    "size_multiplier": 0.0,
                    "reasons": [f"Quote stuffing detected: {stuffing.stuffing_type.value}"],
                    "warnings": ["Market manipulation in progress - avoid trading"]
                }
            elif stuffing.reduce_aggression:
                size_multiplier *= 0.5
                warnings.append(f"Reduce size due to {stuffing.stuffing_type.value}")

        # Check fade signal
        if fade.strength != FadeSignalStrength.NONE and fade.confidence > 0.5:
            action = "trade"
            direction = fade.direction
            confidence = fade.confidence
            reasons.append(
                f"MM inventory fade signal: {fade.strength.value} "
                f"(z-score: {fade.mm_inventory_zscore:.2f})"
            )
            size_multiplier *= fade.max_position_pct / 0.1  # Relative to default

        # Check spread regime
        if spread.is_optimal_entry:
            if action == "trade":
                confidence *= 1.1  # Boost confidence if timing is good
                reasons.append("Optimal spread regime for entry")
            elif spread.entry_score > 0.7:
                reasons.append("Good spread conditions available")
        elif spread.wait_for_tightening:
            if action == "trade" and confidence < 0.7:
                # Wait for better spread if signal isn't strong
                warnings.append(
                    f"Consider waiting - spread may tighten "
                    f"(prob: {spread.tightening_probability:.1%})"
                )
                size_multiplier *= 0.7

        # Spread regime adjustments
        if spread.current_regime in [SpreadRegime.WIDE, SpreadRegime.VERY_WIDE]:
            size_multiplier *= 0.8
            warnings.append(f"Wide spread regime: {spread.current_spread_bps:.1f}bps")
        elif spread.current_regime == SpreadRegime.EXTREME:
            size_multiplier *= 0.5
            warnings.append("Extreme spread - reduce exposure")

        # Cap confidence
        confidence = min(0.95, confidence)

        return {
            "action": action,
            "direction": direction,
            "confidence": confidence,
            "size_multiplier": size_multiplier,
            "reasons": reasons,
            "warnings": warnings,
            "entry_price": fade.entry_price if action == "trade" else None,
            "target_price": fade.target_price if action == "trade" else None,
            "stop_loss": fade.stop_loss if action == "trade" else None,
            "expected_profit_bps": fade.expected_profit_bps if action == "trade" else 0
        }

    def get_trading_decision(
        self,
        venue: str,
        market: str,
        current_price: float,
        current_spread: float,
        urgency: float = 0.5
    ) -> Dict:
        """Get final trading decision"""
        analysis = self.get_comprehensive_analysis(
            venue, market, current_price, current_spread
        )

        recommendation = analysis["recommendation"]

        # Apply urgency modifier
        if urgency > 0.8 and recommendation["action"] == "hold":
            # Override hold if very urgent
            entry_rec = self.spread_regime.get_entry_recommendation(
                venue, market, urgency
            )
            if entry_rec["action"] != "wait":
                recommendation["action"] = "trade"
                recommendation["warnings"].append("High urgency override")

        return {
            "venue": venue,
            "market": market,
            "decision": recommendation["action"],
            "direction": recommendation["direction"],
            "confidence": recommendation["confidence"],
            "size_multiplier": recommendation["size_multiplier"],
            "entry_price": recommendation.get("entry_price"),
            "target_price": recommendation.get("target_price"),
            "stop_loss": recommendation.get("stop_loss"),
            "expected_profit_bps": recommendation.get("expected_profit_bps", 0),
            "reasons": recommendation["reasons"],
            "warnings": recommendation["warnings"],
            "full_analysis": analysis,
            "timestamp": time.time()
        }

    def record_fade_outcome(
        self,
        venue: str,
        market: str,
        signal_timestamp: float,
        entry_price: float,
        exit_price: float,
        direction: str,
        duration_ms: float
    ):
        """Record outcome of a fade trade for calibration"""
        self.inventory_fading.record_outcome(
            venue, market, signal_timestamp, entry_price,
            exit_price, direction, duration_ms
        )

    def get_stats(self) -> Dict:
        """Get engine statistics"""
        return {
            "active_markets": list(self._last_analysis.keys()),
            "total_analyses": len(self._last_analysis)
        }


# =============================================================================
# TEST FUNCTION
# =============================================================================

async def test_mm_exploitation():
    """Test the MM exploitation strategies"""
    print("Testing MM Exploitation Strategies...\n")

    engine = MMExploitationEngine()

    # Simulate market data
    np.random.seed(42)

    base_price = 100.0
    inventory = 0.0

    print("Simulating market activity...")

    for i in range(200):
        # Simulate price movement
        price_change = np.random.randn() * 0.1
        base_price += price_change

        # Simulate inventory buildup (MM accumulating)
        if i < 100:
            inventory += np.random.uniform(0, 10)  # Building long
        else:
            inventory -= np.random.uniform(0, 15)  # Distributing

        # Simulate spread (varies with volatility)
        spread = 0.05 + abs(price_change) * 2

        # Generate order book
        bids = [
            {"price": base_price - 0.01 * (j + 1), "quantity": 100 + np.random.rand() * 50}
            for j in range(5)
        ]
        asks = [
            {"price": base_price + 0.01 * (j + 1), "quantity": 100 + np.random.rand() * 50}
            for j in range(5)
        ]

        # Update engine
        engine.update(
            "kraken", "BTC",
            inventory, base_price, spread,
            bids, asks
        )

        # Simulate some trades
        if i % 5 == 0:
            engine.record_trade(
                "kraken", "BTC",
                base_price + np.random.randn() * 0.01,
                10 + np.random.rand() * 5,
                "buy" if np.random.rand() > 0.5 else "sell"
            )

        await asyncio.sleep(0.01)

    # Get analysis
    print("\n" + "=" * 60)
    print("COMPREHENSIVE ANALYSIS")
    print("=" * 60)

    analysis = engine.get_comprehensive_analysis(
        "kraken", "BTC", base_price, spread
    )

    print("\n--- Inventory Fade Signal ---")
    fade = analysis["fade_signal"]
    print(f"Direction: {fade['direction']}")
    print(f"Strength: {fade['strength']}")
    print(f"Confidence: {fade['confidence']:.2%}")
    print(f"MM Inventory Z-Score: {fade['mm_inventory_zscore']:.2f}")
    print(f"Expected Profit: {fade['expected_profit_bps']:.1f} bps")

    print("\n--- Spread Regime Analysis ---")
    spread_info = analysis["spread_analysis"]
    print(f"Current Regime: {spread_info['current_regime']}")
    print(f"Regime Confidence: {spread_info['regime_confidence']:.2%}")
    print(f"Current Spread: {spread_info['current_spread_bps']:.1f} bps")
    print(f"Is Optimal Entry: {spread_info['is_optimal_entry']}")
    print(f"Entry Score: {spread_info['entry_score']:.2f}")

    print("\n--- Quote Stuffing Alert ---")
    if analysis["stuffing_alert"]:
        stuffing = analysis["stuffing_alert"]
        print(f"Type: {stuffing['stuffing_type']}")
        print(f"Severity: {stuffing['severity']:.2f}")
        print(f"Should Pause: {stuffing['should_pause_trading']}")
    else:
        print("No quote stuffing detected")

    print("\n--- Recommendation ---")
    rec = analysis["recommendation"]
    print(f"Action: {rec['action']}")
    print(f"Direction: {rec['direction']}")
    print(f"Confidence: {rec['confidence']:.2%}")
    print(f"Size Multiplier: {rec['size_multiplier']:.2f}")
    print(f"Reasons: {rec['reasons']}")
    print(f"Warnings: {rec['warnings']}")

    print("\n--- Trading Decision ---")
    decision = engine.get_trading_decision("kraken", "BTC", base_price, spread)
    print(f"Decision: {decision['decision']}")
    print(f"Direction: {decision['direction']}")
    print(f"Confidence: {decision['confidence']:.2%}")

    print("\nTest complete!")


if __name__ == "__main__":
    asyncio.run(test_mm_exploitation())
